<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Artifacts - My Portfolio</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <header>
    <h1>Artifacts</h1>
    <nav>
      <a href="index.html">Back to Home</a>
    </nav>
  </header>

  <section>
    <h2>Project Artifacts</h2>
    <p>Each artifact below follows a consistent structure to demonstrate not only the work delivered, but also its purpose, execution, and relevance to the pharmaceutical data science domain:</p>
    <ul>
      <li><strong>Title</strong></li>
      <li><strong>Introduction</strong></li>
      <li><strong>Description</strong></li>
      <li><strong>Objective</strong></li>
      <li><strong>Process</strong></li>
      <li><strong>Tools/Technologies Used</strong></li>
      <li><strong>Value Proposition</strong> (including Unique Value and Relevance)</li>
      <li><strong>References</strong> (if applicable)</li>
    </ul>
  </section>

  <section class="project">
  <h2>Artifact 1</h2>
  <h3><a href="https://cdn.knightlab.com/libs/timeline3/latest/embed/index.html?source=v2%3A2PACX-1vTUGiuK8fXUhmdAXlSELcUoHBH6zGysA5zKuksJMJ3hoHCp7rmkVAv18SvNkNRxx2VcoJAE78NBYEbR&font=Default&lang=en&initial_zoom=2&width=100%25&height=650" target="_blank">Artificial Intelligence Development Timeline</a></h3>
  <p><strong>Introduction:</strong> A visual timeline that presents major milestones in the history of AI, designed for interactive exploration.</p>
  <p><strong>Description:</strong> This artifact showcases key milestones in AI development from the 1950s to the present. It highlights major achievements, influential figures, and paradigm shifts, including AI winters and the rise of deep learning.</p>
  <p><strong>Objective:</strong> To provide a clear, engaging historical overview of artificial intelligence that highlights its evolution and key contributors.</p>
  <p><strong>Process:</strong> Curated historical data from verified sources, structured events into a Google Sheet, and deployed the visualization via Knight Lab’s TimelineJS.</p>
  <p><strong>Tools/Technologies Used:</strong> TimelineJS, Google Sheets, HTML</p>
  <p><strong>Value Proposition:</strong> Enhances historical understanding for students, educators, and professionals by offering a centralized, interactive learning tool on AI development.</p>
</section>

<section class="project">
  <h2>Artifact 2</h2>
  <h3>Comparative Analysis: Machine Learning vs. Deep Learning</h3>
  <p><strong>Introduction:</strong> This artifact presents a structured comparison of machine learning and deep learning through real-world use cases.</p>
  <p><strong>Description:</strong> Using a table-based analysis, the artifact outlines three application domains: medical diagnostics, disease progression prediction, and autonomous driving to highlight why either machine learning or deep learning is preferred. The table evaluates each approach based on suitability and explains why the alternative is less effective in context.</p>
  <p><strong>Objective:</strong> To provide practical guidance on selecting appropriate modeling approaches by contrasting their advantages, interpretability, and limitations in specific domains.</p>
  <p><strong>Process:</strong> Evaluated representative scenarios and mapped them into a structured comparison. Justified model selection by interpretability, data characteristics, and computational considerations.</p>
  <p><strong>Tools/Technologies Used:</strong> HTML table formatting for structured comparison</p>
  <p><strong>Value Proposition:</strong> This artifact equips practitioners with a clear understanding of the fundamental differences between machine learning and deep learning. By presenting contextual strengths and limitations, it helps data professionals make informed decisions about which modeling approach to use. The comparative format empowers users to evaluate factors like data size, interpretability, and complexity, ensuring the chosen method aligns with the problem’s requirements and constraints.</p>

  <table style="width:100%; border-collapse: collapse; margin-top: 20px;" border="1" cellpadding="10">
    <thead style="background-color:#f2f2f2;">
      <tr>
        <th>Real-world Application</th>
        <th>Why the Approach is Suitable</th>
        <th>Why the Other Approach is Not Suitable</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td><strong>Logistic Regression</strong><br>Medical diagnostics: Predict whether a tumor is benign or malignant</td>
        <td>Highly interpretable, critical in clinical trials; regulators like FDA need transparency into how features contribute to decisions</td>
        <td>Deep learning models are black-box, require more data and computation; unnecessary for small, structured datasets</td>
      </tr>
      <tr>
        <td><strong>Linear Regression</strong><br>Predict disease progression and its relation to prognostic factors</td>
        <td>Works well with small datasets common in clinical trials; interpretable relationships between variables and outcomes</td>
        <td>Deep learning may overfit small datasets and lacks clear interpretation of prognostic factors</td>
      </tr>
      <tr>
        <td><strong>Convolutional Neural Networks (CNNs)</strong><br>Autonomous vehicles and computer vision tasks</td>
        <td>Efficient for processing raw, high-dimensional image data; enables real-time, scalable, and accurate object recognition</td>
        <td>Machine learning requires pre-extracted features and cannot process raw image/video data directly</td>
      </tr>
    </tbody>
  </table>
</section>


  </section>
